{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "479c7b60",
   "metadata": {},
   "source": [
    "# Finetuning Adam Notebook\n",
    "------------------\n",
    "This notebook contains the code used to train the models with the Adam optimizer. \n",
    "\n",
    "It functions primarily on Google Colab, but can be adapted to work on local hardware.\n",
    "\n",
    "It trains only one type of model and searches through hyperparameters with a Grid Search algorithm.\n",
    "\n",
    "For each model type, minimal adjustments need to be made before running the code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228af356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# This script mounts Google Drive in a Google Colab environment.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96d231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/OptiML/repo/OptML-project\n"
     ]
    }
   ],
   "source": [
    "# Set the current working directory to a specific path in Google Drive.\n",
    "%cd /content/drive/MyDrive/OptiML/repo/OptML-project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751f074c",
   "metadata": {},
   "source": [
    "## Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for the project.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "from Functions.implementations import * # Import custom implementations, these contain the model definitions and training functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d46faf",
   "metadata": {},
   "source": [
    "# Training with Adam optimizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#only for google Colab :\n",
    "\n",
    "# Set a path in your Google Drive\n",
    "csv_path = \"/content/drive/MyDrive/OptiML/Results/Adam_VGG_new.csv\"\n",
    "save_path = \"/content/drive/MyDrive/OptiML/Results/Adam_VGG_new\"\n",
    "# For local machine, set the path to your desired location\n",
    "\n",
    "# Set the number of epochs and evaluation interval\n",
    "epochs = 100\n",
    "eval_interval = 10 # Interval for evaluation and saving results\n",
    "\n",
    "# Create the CSV with headers if it doesn't exist\n",
    "if not os.path.exists(csv_path):\n",
    "    columns = [\"learning_rate\", \"beta_1\",\"beta_2\"] +  [f\"epoch_{i}\" for i in range(epochs//eval_interval, epochs + 1, eval_interval)] + [\"Test\"]\n",
    "    pd.DataFrame(columns=columns).to_csv(csv_path, index=False)\n",
    "\n",
    "set_seed(42) # Set seed for reproducibility through custom function as done throughtout the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define the device to use for training (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function to get data loaders for training, validation, and testing\n",
    "train_loader,valid_loader, test_loader = get_data_loaders(batch_size=128)\n",
    "\n",
    "# Set up a dictionary to store results\n",
    "results_grid = {}\n",
    "\n",
    "# Define the hyperparameters for the grid search (for VGG-like model, extra values wer used to find the best range to tune in)\n",
    "learning_rates = [1e-3, 5e-4, 1e-4] # Extra parameters for VGG-like model : 1e-2, 5e-3, 2e-3\n",
    "beta_1s = [0.95, 0.9, 0.8] # Extra parameters for VGG-like model : 0.5\n",
    "beta_2s = [0.99, 0.999, 0.9999] # Extra parameters for VGG-like model : 0.98 and 0.5\n",
    "\n",
    "# Iterate over all combinations of lr , beta_1, and beta_2\n",
    "for lr, beta_1, beta_2 in product(learning_rates, beta_1s, beta_2s):\n",
    "    scores, model = train_and_return_evaluation_Adam(\n",
    "        VGGLike, # Model type that needs to be trained, needs to be changed for different model types. Options are defined in the implementations.py file.\n",
    "        lr=lr,\n",
    "        beta_1=beta_1,\n",
    "        beta_2=beta_2,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=valid_loader,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        epochs=epochs,\n",
    "        eval_interval=eval_interval\n",
    "    )\n",
    "    results_grid[(lr, beta_1, beta_2)] = scores # Store the scores for each combination of hyperparameters\n",
    "\n",
    "    # Extract F1 scores only, for CSV export\n",
    "    f1_scores = [f1 for (_, _, _, f1) in scores]\n",
    "    \n",
    "    # Create a row for the CSV\n",
    "    row = [lr, beta_1, beta_2] + f1_scores\n",
    "\n",
    "    # Append to CSV\n",
    "    df_row = pd.DataFrame([row])\n",
    "    df_row.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), save_path + f\"/VGG_lr_{lr}_beta1_{beta_1}_beta2_{beta_2}.pth\") # Save the model with a unique name based on hyperparameters and model type"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
