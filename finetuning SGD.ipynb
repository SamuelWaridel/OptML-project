{"cells":[{"cell_type":"markdown","metadata":{"id":"CO2mWP4U6VP6"},"source":["# Main Notebook for running code"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22897,"status":"ok","timestamp":1744876642791,"user":{"displayName":"Timothee Coester","userId":"01041092910576296196"},"user_tz":-120},"id":"_JXVO_cJ6jPO","outputId":"6a95d819-321b-4bb1-8bea-0c636ebdeb62"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":748,"status":"ok","timestamp":1744876645237,"user":{"displayName":"Timothee Coester","userId":"01041092910576296196"},"user_tz":-120},"id":"_yLPZ9BW6spJ","outputId":"07e216d3-9042-4cde-f653-a647865eed50"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/OptiML/repo/OptML-project\n"]}],"source":["%cd /content/drive/MyDrive/OptiML/repo/OptML-project"]},{"cell_type":"markdown","metadata":{"id":"zPJj0dva6VP-"},"source":["## Global Imports"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":12874,"status":"ok","timestamp":1744876659785,"user":{"displayName":"Timothee Coester","userId":"01041092910576296196"},"user_tz":-120},"id":"N271CvH86VP_"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","import sklearn\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torchvision import datasets, transforms\n","from sklearn.metrics import accuracy_score, recall_score, f1_score\n","from Functions.implementations import *"]},{"cell_type":"markdown","metadata":{"id":"MIlnAeS06VQA"},"source":["## Load Data"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":11362,"status":"ok","timestamp":1744876799546,"user":{"displayName":"Timothee Coester","userId":"01041092910576296196"},"user_tz":-120},"id":"JNDjAV2f6VQB"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = SimpleCNN().to(device)\n","train_loader,valid_loader, test_loader = get_data_loaders()"]},{"cell_type":"markdown","metadata":{"id":"Jo3A5BJ_6VQB"},"source":["Train and evaluate a simple model to test if everything works."]},{"cell_type":"markdown","metadata":{"id":"MzGYXB1z6VQC"},"source":["## SGD :"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1744876844786,"user":{"displayName":"Timothee Coester","userId":"01041092910576296196"},"user_tz":-120},"id":"fC5fGgKm6VQC"},"outputs":[],"source":["import os\n","\n","#only for google Colab :\n","\n","# Set a path in your Google Drive\n","csv_path = \"/content/drive/MyDrive/OptiML/repo/OptML-project_SGD_VGGLike_Transform.csv\"\n","save_path = \"/content/drive/MyDrive/OptiML/repo/OptML-project/Results/SGD\"\n","# For local machine, set the path to your desired location\n","#save_path = os.getcwd() + \"/Results/SGD\"\n","#csv_path = save_path + \"/sgd_gridsearch_results.csv\"\n","\n","\n","epochs = 100\n","eval_interval = 10\n","\n","# Create the CSV with headers if it doesn't exist\n","if not os.path.exists(csv_path):\n","    columns = [\"learning_rate\", \"momentum\"] +  [f\"epoch_{i}\" for i in range(epochs//eval_interval, epochs + 1, eval_interval)] + [\"Test\"]\n","    pd.DataFrame(columns=columns).to_csv(csv_path, index=False)\n","\n","set_seed(42) # Set a random seed for reproducibility"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"xlm6NBac6VQD"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","ðŸ”§ Training with SGD: lr=0.05, momentum=0.6\n","Epoch 10 | Acc=0.7882 | Recall=0.7883 | F1=0.7868\n","Epoch 20 | Acc=0.8156 | Recall=0.8157 | F1=0.8124\n","Epoch 30 | Acc=0.8438 | Recall=0.8440 | F1=0.8440\n","Epoch 40 | Acc=0.8480 | Recall=0.8485 | F1=0.8488\n","Epoch 50 | Acc=0.8420 | Recall=0.8423 | F1=0.8423\n","Epoch 60 | Acc=0.8514 | Recall=0.8507 | F1=0.8505\n","Epoch 70 | Acc=0.8574 | Recall=0.8575 | F1=0.8574\n","Epoch 80 | Acc=0.8592 | Recall=0.8589 | F1=0.8592\n","Epoch 90 | Acc=0.8422 | Recall=0.8424 | F1=0.8438\n","Epoch 100 | Acc=0.8540 | Recall=0.8544 | F1=0.8545\n","\n","Test Set Evaluation: Acc=0.8650 | Recall=0.8650 | F1=0.8652\n","\n","ðŸ”§ Training with SGD: lr=0.01, momentum=0.6\n","Epoch 10 | Acc=0.6124 | Recall=0.6120 | F1=0.6009\n","Epoch 20 | Acc=0.7536 | Recall=0.7541 | F1=0.7521\n","Epoch 30 | Acc=0.7876 | Recall=0.7866 | F1=0.7884\n","Epoch 40 | Acc=0.8230 | Recall=0.8237 | F1=0.8226\n","Epoch 50 | Acc=0.8238 | Recall=0.8243 | F1=0.8256\n","Epoch 60 | Acc=0.8378 | Recall=0.8377 | F1=0.8372\n","Epoch 70 | Acc=0.8350 | Recall=0.8359 | F1=0.8354\n","Epoch 80 | Acc=0.8452 | Recall=0.8447 | F1=0.8448\n","Epoch 90 | Acc=0.8446 | Recall=0.8449 | F1=0.8451\n"]}],"source":["from itertools import product\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train_loader,valid_loader, test_loader = get_data_loaders(batch_size=128)\n","\n","results_grid = {}\n","\n","# learning_rates = [5e-2, 1e-2, 5e-3, 1e-3]\n","# momentums = [0.0, 0.6, 0.9, 0.99]\n","\n","learning_rates = [5e-2, 1e-2, 5e-3, 1e-3]\n","momentums = [0.6]\n","\n","# Iterate over all combinations of lr and momentum\n","\n","for lr, momentum in product(learning_rates, momentums):\n","    scores, model = train_and_return_evaluation_SGD(\n","        VGGLike,\n","        lr=lr,\n","        momentum=momentum,\n","        train_loader=train_loader,\n","        valid_loader=valid_loader,\n","        test_loader=test_loader,\n","        device=device,\n","        epochs=epochs,\n","        eval_interval=eval_interval\n","    )\n","    results_grid[(lr, momentum)] = scores\n","\n","    # Extract F1 scores only, for CSV export\n","    f1_scores = [f1 for (_, _, _, f1) in scores]\n","\n","    row = [lr, momentum] + f1_scores\n","\n","    # Append to CSV\n","    df_row = pd.DataFrame([row])\n","    df_row.to_csv(csv_path, mode='a', header=False, index=False)\n","\n","    # Save the model\n","    torch.save(model.state_dict(), save_path + f\"/VGG_Transform_lr_{lr}_momentum_{momentum}.pth\")"]},{"cell_type":"markdown","metadata":{"id":"phHlE2TP6VQD"},"source":["# Adam :"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TxbI7F426VQD"},"outputs":[],"source":["import os\n","\n","#only for google Colab :\n","\n","# Set a path in your Google Drive\n","#csv_path = \"/content/drive/MyDrive/OptiML/sgd_gridsearch_results.csv\"\n","\n","# For local machine, set the path to your desired location\n","save_path = os.getcwd() + \"/Results/Adam\"\n","csv_path = save_path + \"/adam_gridsearch_results.csv\"\n","\n","# Set number of epochs and evaluation interval\n","epochs = 100\n","eval_interval = 10\n","\n","# Create the CSV with headers if it doesn't exist\n","if not os.path.exists(csv_path):\n","    columns = [\"learning_rate\", \"momentum\"] +  [f\"epoch_{i}\" for i in range(epochs//eval_interval, epochs + 1, eval_interval)] + [\"Test\"]\n","    pd.DataFrame(columns=columns).to_csv(csv_path, index=False)\n","\n","set_seed(42) # Set a random seed for reproducibility"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hGXV-LJf6VQE"},"outputs":[],"source":["from itertools import product\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","train_loader, test_loader = get_data_loaders(batch_size=128)\n","\n","results_grid = {}\n","\n","# learning_rates = [5e-2, 1e-2, 5e-3, 1e-3]\n","# betas = [(0.9, 0.999), (0.8, 0.999), (0.9, 0.99)]\n","\n","learning_rates = [1e-2]\n","betas = [(0.9, 0.999), (0.8, 0.999), (0.9, 0.99)]\n","\n","# Iterate over all combinations of lr and momentum\n","for lr, betas in product(learning_rates, betas):\n","    scores = train_and_return_evaluation_Adam(\n","        VGGLike,\n","        lr=lr,\n","        betas=betas,\n","        train_loader=train_loader,\n","        test_loader=test_loader,\n","        device=device,\n","        epochs=epochs,\n","        eval_interval=eval_interval\n","    )\n","    results_grid[(lr, betas[0], betas[1])] = scores\n","\n","    # Extract F1 scores only, for CSV export\n","    f1_scores = [f1 for (_, _, _, f1) in scores]\n","\n","    row = [lr, betas[0], betas[1]] + f1_scores\n","\n","    # Append to CSV\n","    df_row = pd.DataFrame([row])\n","    df_row.to_csv(csv_path, mode='a', header=False, index=False)\n","\n","    # Save the model\n","    torch.save(model.state_dict(), save_path + f\"/model_lr_{lr}_beta1_{betas[0]}_beta2_{betas[2]}.pth\")"]},{"cell_type":"markdown","metadata":{"id":"ZvRU1mqf6VQE"},"source":["Test on colab :\n","\n","lr = 0.05\n","- (0.9, 0.999) : F1 ~ 0.18\n","- (0.8, 0.999) : F1 ~ 0.18\n","- (0.9, 0.99) : F1 ~\n","\n","lr = 0.01\n","- (0.9, 0.999) : F1 ~\n","- (0.8, 0.999) : F1 ~\n","- (0.9, 0.99) : F1 ~\n","\n","lr = 0.005\n","- (0.9, 0.999) : F1 ~\n","- (0.8, 0.999) : F1 ~\n","- (0.9, 0.99) : F1 ~\n","\n","lr = 0.001\n","- (0.9, 0.999) : F1 ~\n","- (0.8, 0.999) : F1 ~\n","- (0.9, 0.99) : F1 ~"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CxNfHTNZ6VQE"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.2"}},"nbformat":4,"nbformat_minor":0}